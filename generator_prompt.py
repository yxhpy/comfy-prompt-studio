import requests
import json
import os
from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables
load_dotenv()

def chat_with_ollama(model_name, prompt, stream=False):
    """
    Call Ollama API to chat with a model

    Args:
        model_name: Name of the model (e.g., 'huihui_ai/qwen3-abliterated:30b')
        prompt: The prompt/question to send to the model
        stream: Whether to stream the response

    Returns:
        The model's response
    """
    url = "http://localhost:11434/api/generate"

    payload = {
        "model": model_name,
        "prompt": prompt,
        "stream": stream
    }

    response = requests.post(url, json=payload)

    if stream:
        # Handle streaming response
        full_response = ""
        for line in response.iter_lines():
            if line:
                json_response = json.loads(line)
                if 'response' in json_response:
                    chunk = json_response['response']
                    print(chunk, end='', flush=True)
                    full_response += chunk
        print()  # New line at the end
        return full_response
    else:
        # Handle non-streaming response
        result = response.json()
        return result.get('response', '')


def chat_conversation(model_name, messages, stream=False, callback=None):
    """
    Have a conversation using the chat endpoint

    Args:
        model_name: Name of the model
        messages: List of message dicts with 'role' and 'content'
        stream: Whether to stream the response
        callback: Function to call for each chunk (only used when stream=True)

    Returns:
        The assistant's response
    """
    url = "http://localhost:11434/api/chat"

    payload = {
        "model": model_name,
        "messages": messages,
        "stream": stream
    }

    response = requests.post(url, json=payload, stream=stream)

    if stream:
        # Handle streaming response
        full_response = ""
        for line in response.iter_lines():
            if line:
                json_response = json.loads(line)
                if 'message' in json_response and 'content' in json_response['message']:
                    chunk = json_response['message']['content']
                    full_response += chunk
                    if callback:
                        callback(chunk)
                    else:
                        print(chunk, end='', flush=True)
        if not callback:
            print()  # New line at the end
        return full_response
    else:
        result = response.json()
        return result.get('message', {}).get('content', '')


def chat_with_gemini(messages, stream=False, callback=None):
    """
    Have a conversation using Gemini API via OpenAI-compatible endpoint

    Args:
        messages: List of message dicts with 'role' and 'content'
        stream: Whether to stream the response
        callback: Function to call for each chunk (only used when stream=True)

    Returns:
        The assistant's response
    """
    api_key = os.getenv('GEMINI_API_KEY')
    model_name = os.getenv('GEMINI_MODEL', 'gemini-2.0-flash-exp')
    base_url = os.getenv('GEMINI_BASE_URL', 'https://api.laozhang.ai/v1/')

    client = OpenAI(
        api_key=api_key,
        base_url=base_url
    )

    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=messages,
            stream=stream
        )

        if stream:
            full_response = ""
            for chunk in response:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_response += content
                    if callback:
                        callback(content)
                    else:
                        print(content, end='', flush=True)
            if not callback:
                print()  # New line at the end
            return full_response
        else:
            return response.choices[0].message.content
    except Exception as e:
        print(f"âŒ Gemini API é”™è¯¯: {str(e)}", flush=True)
        raise

# æç¤ºè¯ç¼“å­˜
_prompt_cache = {}

def generate_prompt(user_req: str, stream=False, log_callback=None):
    """
    ç”Ÿæˆæç¤ºè¯ï¼Œå¸¦ç¼“å­˜æœºåˆ¶

    Args:
        user_req: ç”¨æˆ·éœ€æ±‚æè¿°
        stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
        log_callback: æ—¥å¿—å›è°ƒå‡½æ•°ï¼Œç”¨äºå®æ—¶è¾“å‡ºæ—¥å¿—

    Returns:
        (positive_prompt, negative_prompt) å…ƒç»„
    """
    def log(msg):
        """ç»Ÿä¸€çš„æ—¥å¿—è¾“å‡ºå‡½æ•°"""
        print(msg, flush=True)
        if log_callback:
            log_callback(msg)

    # æ£€æŸ¥ç¼“å­˜
    if user_req in _prompt_cache:
        log(f"âœ… ä½¿ç”¨ç¼“å­˜çš„æç¤ºè¯ï¼ˆç”¨æˆ·éœ€æ±‚: {user_req[:30]}...ï¼‰")
        return _prompt_cache[user_req]

    # è·å– AI Provider é…ç½®
    provider = os.getenv('AI_PROVIDER', 'ollama').lower()
    log(f"ğŸ¤– ä½¿ç”¨ AI Provider: {provider}")

    # ç”Ÿæˆæ–°çš„æç¤ºè¯
    log(f"ğŸ”„ ç”Ÿæˆæ–°çš„æç¤ºè¯ï¼ˆç”¨æˆ·éœ€æ±‚: {user_req[:30]}...ï¼‰")

    messages = [
        {"role": "system", "content": """
# role
ä½ æ˜¯ä¸€ä¸ªcomfyuiçš„æç¤ºè¯è®¾è®¡å¤§å¸ˆï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·è®¾è®¡ç¬¦åˆcomfyuiè¦æ±‚çš„æç¤ºè¯

# æ­£é¢-è´Ÿé¢æç¤ºè¯æ ·ä¾‹
## group1
- (masterpiece,best quality,score_9, score_8_up, score_7_up:1),RAW,dynamic angle, sitting on a park bench,(night:1.5), 1girl,long hair,hair,make up,red lipstick,black eyes,air bangs,large breasts,bracelet,round earrings, blush,sexy,pose,posing,closeup,selfie, nipples,areolas,south korea idol,lace (see-through dress),necklace,jewelry,shoulder strap dress,breasts out,depth of field,bokeh
- (score_6,score_5,score_4,score_3, score_2, score_1:1),source_furry,source_pony,source_cartoon,female child dark-skinned female,day,(blurry:1.4),(blurred foreground)
## group2
- a asian woman wearing (hanfu:1.2), solo, nude,nipples, breasts, (chinese clothes:1.2), open clothes, breasts out,black hair, pale skin, hair ornament, bamboo, hair flower, flower, sitting, looking at viewer, long hair, long sleeves,nipples,areolas, bare shoulders, plant, lips, ass visible through thighs, sitting and spread legs,pussy,makeup,red lips,forest background
- female child, dark-skinned female, signature,username,text,watermark, illustration,3d,2d,painting,cartoons,sketch
## group3
- r/adorableporn, masterpiece, highres, best quality, highly detailed, 19yo petite girl lying, brunette, navel, (huge breasts:1.2), large vaginal penetration, missionary, man, veiny penis, side view, wild beach at night
- worst quality, low quality, 3d, 2d, painting, sketch, text, watermark, threesome, chubby, pov, blurry, latina
## group4
- she is giving a blowjob to a man's penis in a 69 position,face close-up,deepthroat,A 25-year-old cute Japanese woman,young, testicles close-up, a man, looking at viewer, male pubic hair, wide-eyed, testicles, eyelashes, female on top, oral, penis, from front, nude, breasts, solo focus, black hair, makeup, mascara, short hair,bangs
- pov crotch,pussy,full body,from side,sex,worst quality,low quality,lowres,illustration,3d,2d,painting,cartoons,anime,painting,CGI,3D render,bad anatomy,sketch,photoshop,airbrushed skin,overexposed,watermark,text,logo,label,blurry, blurry foreground
## group5
- score_7_up,Photo (from below:1.4),naked photo of an 18-year-old female korean idol ,pale skin,black eyes,small breasts, nipples, comfortable expression,solo, long hair, black hair, nude, navel, pussy, teeth,makeup,lipstick,(arms behind back:1.2), (peeing:1.4555),arms behind head, open mouth, red lips,blunt bangs,She squatted on the grass wearing high heels and peed, pee spurted from her pussy and (the floor was filled with her yellow urine), pee gushing out of her pussy,labia,clitoris,She urinates in front of the camera,knees up,m legs,looking at viewer, parted lips,collarbone,  teeth, open mouth, indoors,spread legs,ass visible through thighs,(pussy close-up:1.2),outdoors,park background, trees
- kneeling (score_6,score_5,score_4,score_3,score_2,score_1:1),dark-skinned female,source_furry,source_pony,source_cartoon,illustration,3d,2d,painting,cartoons,sketch,female child,signature,username,text,watermark,

# æç¤ºè¯æ–‡æ¡£
## ğŸ¯ ä»€ä¹ˆæƒ…å†µä¸‹ç”¨ä»€ä¹ˆæç¤ºè¯

### 1. **è´¨é‡æ§åˆ¶åœºæ™¯**
- **è¿½æ±‚æœ€é«˜è´¨é‡**ï¼š`score_9`
- **é«˜è´¨é‡ç”Ÿæˆ**ï¼š`score_8_up`
- **å¹³è¡¡è´¨é‡ä¸å¤šæ ·æ€§**ï¼š`score_7_up`ï¼ˆæ¨èï¼‰
- **æ›´å¤šå˜åŒ–**ï¼š`score_5_up`

### 2. **å†…å®¹åˆ†çº§åœºæ™¯**
- **å®‰å…¨å†…å®¹**ï¼š`SFW`
- **æˆäººå†…å®¹**ï¼š`NSFW`
- **æš—ç¤ºæ€§å†…å®¹**ï¼š`Suggestive`

### 3. **æ‘„å½±é£æ ¼åœºæ™¯**
- **ä¸“ä¸šæ‘„å½±**ï¼š`DSLR`, `photo (medium)`
- **æ™¯æ·±æ•ˆæœ**ï¼š`depth_of_field`
- **è‡ªç„¶å…‰çº¿**ï¼š`natural lighting`
- **äººå·¥å…‰æº**ï¼š`neon lights`, `warm lighting`

### 4. **æ¥æºå¹³å°åœºæ™¯**
- **ç¤¾äº¤åª’ä½“é£æ ¼**ï¼š`reddit`, `instagram`, `flickr`, `unsplash`
- **ç‰¹å®šç¤¾åŒº**ï¼š`r/asstastic`, `r/earthporn`

## ğŸ“ å®Œæ•´æç¤ºè¯åˆ—è¡¨

### **è´¨é‡è¯„åˆ†æ ‡ç­¾**ï¼ˆå¿…é¡»åœ¨å¼€å¤´ï¼‰
```
score_9, score_8_up, score_7_up, score_6_up, score_5_up
score_8, score_7, score_6, score_5
```

### **å†…å®¹åˆ†çº§æ ‡ç­¾**
```
SFW, NSFW, Suggestive
```

### **åª’ä»‹ç±»å‹æ ‡ç­¾**
```
photo (medium), DSLR, photograph, digital photo
```

### **äººç‰©ç›¸å…³æ ‡ç­¾**
```
1girl, 1boy, 2girls, multiple people
long hair, short hair, blonde hair, black hair, brown hair
blue eyes, brown eyes, green eyes
small breasts, large breasts, medium breasts
standing, sitting, lying, kneeling
nude, clothed, partially clothed
```

### **æœè£…æ ‡ç­¾**
```
dress, shirt, skirt, pants, jeans
bikini, lingerie, underwear
thighhighs, stockings, pantyhose
high heels, boots, sneakers
jewelry, necklace, earrings
```

### **åœºæ™¯ç¯å¢ƒæ ‡ç­¾**
```
indoor, outdoor, bedroom, kitchen, bathroom
beach, forest, city, street, park
sunset, sunrise, night, day
rain, snow, cloudy, sunny
```

### **æ‘„å½±æŠ€æœ¯æ ‡ç­¾**
```
depth_of_field, bokeh, macro, close-up
wide shot, medium shot, portrait
natural lighting, studio lighting
soft shadows, hard shadows
high contrast, low contrast
```

### **ç›¸æœºè®¾å¤‡æ ‡ç­¾**
```
Canon EOS, Nikon, Sony
35mm, 50mm, 85mm, 135mm
f/1.4, f/2.8, f/5.6
ISO 100, ISO 400, ISO 800
```

### **è‰ºæœ¯é£æ ¼æ ‡ç­¾**
```
realistic, photorealistic, hyperrealistic
vintage, retro, modern, contemporary
black and white, sepia, color
film grain, sharp, soft
```

### **æ¥æºå¹³å°æ ‡ç­¾**
```
reddit, instagram, flickr, unsplash
r/earthporn, r/portraits, r/photography
```

### **ç‰¹æ®Šæ•ˆæœæ ‡ç­¾**
```
watermark (é¿å…ä½¿ç”¨ï¼Œæ”¾è´Ÿé¢æç¤ºè¯)
text "å†…å®¹" (ç”ŸæˆæŒ‡å®šæ–‡å­—)
motion blur, lens flare
vignette, chromatic aberration
```

### **èº«ä½“éƒ¨ä½ç»†èŠ‚æ ‡ç­¾**
```
detailed hands, detailed edges (æ‰‹éƒ¨ç›¸å…³å¿…åŠ )
detailed face, detailed eyes
detailed skin, skin texture
freckles, moles, scars
```

## ğŸš« è´Ÿé¢æç¤ºè¯æ¨è
```
score_1, score_2, score_3, watermark, low quality, blurry, 
out of focus, bad anatomy, deformed, mutated, extra limbs,
missing limbs, bad hands, bad feet, text, signature, username
```

## ğŸ’¡ å®ç”¨æç¤ºè¯ç»„åˆ

### **äººåƒæ‘„å½±**
```
score_8_up, photo (medium), portrait, 1girl, detailed face, 
natural lighting, depth_of_field, Canon EOS, 85mm, f/1.4
```

### **é£æ™¯æ‘„å½±**
```
score_7_up, landscape photography, golden hour, depth_of_field,
wide shot, natural lighting, high resolution, detailed
```

### **è¡—æ‹é£æ ¼**
```
score_7_up, street photography, candid, natural pose, 
urban environment, natural lighting, 35mm, documentary style
```

### **ä¸“ä¸šæ‘„å½±**
```
score_8_up, professional photography, studio lighting, 
high quality, detailed, DSLR, commercial photography
```
### æ¶‰åŠé˜´éƒ¨
```
Recreates large and long labia, the exact opposite of an innie. Activate with `LABIAXXL`. Additional helpful prompts below. Please post your gens and leave feedback/advice, as this is my first semi-successful lora.

Spread legs
Spread pussy
Rear view
Large labia
Pussy juice
Clitoris/clitoral hood/urethra
```

### æ‹ç…§é£æ ¼
```
trigger word-è§¦å‘è¯:

Polaroid,

film photography,

film grain,

film particles,

grainy,

Raw format,

studio lighting,

flash photography,

analog photography aesthetic,

computational photography and Mobile phone image quality,

computational photography and Landline image quality,

computational photography and Pager image quality,

ultrahigh-res,

double exposure,

Fuji C100 shootingã€Fuji C200 shootingã€Kodak 400 shootingã€Kodak gold 200 shootingã€Nolan 5219 shooting

--

Negativ-è´Ÿé¢:

overexposed background,

poor lighting,

overexposed areas,

uneven lighting,

Low resolution,

potential compression artifact,
```

è¿™äº›æç¤ºè¯å¯ä»¥æ ¹æ®éœ€è¦è‡ªç”±ç»„åˆä½¿ç”¨ï¼Œè®°ä½è´¨é‡æ ‡ç­¾å¿…é¡»æ”¾åœ¨æœ€å‰é¢ï¼

# ä»»åŠ¡
- æ‹“å±•æè¿°ï¼Œç¦æ­¢å‡ºç°æ¨¡ç³Šçš„æ¦‚å¿µï¼Œå¦‚ç¾ä¸½çš„è„¸éƒ¨ï¼Œè¿™é‡Œéœ€è¦æ¸…æ™°çš„æè¿°è„¸éƒ¨ï¼Œé¼»å­çœ‰æ¯›è€³æœµç­‰ç»†èŠ‚
- ä½ éœ€è¦æ ¹æ®ç”¨æˆ·è¾“å…¥çš„æè¿°ï¼Œè¾“å‡ºç¬¦åˆç›®æ ‡æ ·ä¾‹çš„æç¤ºè¯ï¼Œæç¤ºè¯åŒ…å«è¿”å›ç»“æœä¸­å¿…é¡»åŒ…å«æ­£é¢æç¤ºè¯å’Œè´Ÿé¢æç¤ºè¯
- ç”Ÿæˆçš„æç¤ºè¯å¿…é¡»æ»¡è¶³ç”¨æˆ·çš„éœ€æ±‚ï¼Œä¸èƒ½è¶…å‡ºç”¨æˆ·çš„æè¿°
- å…ˆæ€è€ƒ æ€è€ƒè¿‡ç¨‹æ”¾åˆ°<think></think>ä¸­
- è¿”å›æç¤ºè¯åŒ…å«æ­£é¢å’Œåé¢æç¤ºè¯<positive_prompt></positive_prompt><negative_prompt></negative_prompt>
- æç¤ºè¯ä¸­ï¼Œå…ˆä¸€å¥è‹±è¯­æè¿°ä¸»è¦å†…å®¹ï¼Œä»»åŠ¡æ—¶é—´åœ°ç‚¹äº‹ä»¶ç­‰ï¼Œå†åˆ†è¯æè¿°ç»†èŠ‚ï¼Œæ¯ä¸ªåˆ†è¯ä¹‹é—´ç”¨é€—å·éš”å¼€
- å¦‚æœæç¤ºè¯ä¸­æ¶‰åŠåˆ°æ‰‹éƒ¨ï¼Œå¿…é¡»åŠ ä¸Šè¿™äº›æç¤ºè¯ 'detailed hands,detailed edges'
- æç¤ºè¯éµå®ˆ bigASP è¯­æ³• 

# è¿”å›æ ·ä¾‹
<positive_prompt>æ­£é¢æç¤ºè¯</positive_prompt>
<negative_prompt>è´Ÿé¢æç¤ºè¯</negative_prompt>
"""},
    ]
    messages.append({"role": "user", "content": user_req})

    # å®šä¹‰æµå¼å›è°ƒå‡½æ•°
    stream_buffer = []
    def stream_callback(chunk):
        """å¤„ç†æµå¼è¾“å‡ºçš„æ¯ä¸ªchunk"""
        stream_buffer.append(chunk)
        if log_callback:
            log_callback(chunk)
        else:
            print(chunk, end='', flush=True)

    # æ ¹æ® provider è°ƒç”¨ä¸åŒçš„ API
    log(f"ğŸ“¡ å¼€å§‹è°ƒç”¨ AI ç”Ÿæˆæç¤ºè¯...")
    if provider == 'gemini':
        response = chat_with_gemini(messages, stream=stream, callback=stream_callback if stream else None)
    else:  # default to ollama
        model = os.getenv('OLLAMA_MODEL', 'huihui_ai/qwen3-abliterated:30b')
        response = chat_conversation(model, messages, stream=stream, callback=stream_callback if stream else None)

    if stream and not log_callback:
        print()  # æ¢è¡Œ

    log(f"âœ… AI ç”Ÿæˆå®Œæˆï¼Œå¼€å§‹è§£ææç¤ºè¯...")

    positive_prompt = response.split("<positive_prompt>")[1].split("</positive_prompt>")[0]
    negative_prompt = response.split("<negative_prompt>")[1].split("</negative_prompt>")[0]

    # ç¼“å­˜ç»“æœ
    _prompt_cache[user_req] = (positive_prompt, negative_prompt)
    log(f"ğŸ’¾ æç¤ºè¯å·²ç¼“å­˜ï¼Œç¼“å­˜æ•°é‡: {len(_prompt_cache)}")

    return positive_prompt, negative_prompt

def clear_cache():
    """æ¸…ç©ºæç¤ºè¯ç¼“å­˜"""
    global _prompt_cache
    cache_size = len(_prompt_cache)
    _prompt_cache = {}
    print(f"ğŸ—‘ï¸ å·²æ¸…ç©ºæç¤ºè¯ç¼“å­˜ï¼Œæ¸…é™¤äº† {cache_size} æ¡è®°å½•", flush=True)
    return cache_size
if __name__ == "__main__":
    positive_prompt, negative_prompt = generate_prompt(
        "8kç…§ç‰‡ï¼Œä¸€ä¸ªè€å¸ˆç©¿ç€olåœ¨æ•™å®¤é‡Œè‡ªæ…°ï¼Œåç€mè…¿æŠ¬èµ·å±è‚¡ï¼Œæ‰‹æ”¾åœ¨å¤§è…¿ï¼Œæ°å¼€å¤§è…¿é¢å‘è§‚ä¼—å±•ç¤ºé˜´éƒ¨ã€‚ç²¾è‡´çš„é…é¥°ï¼Œå·å‘ï¼Œé•¿å‘ï¼Œè£¸è„šï¼Œç©¿ç€ä¸è¢œï¼Œèº«æä¹å¤´èº«ï¼Œå·¨ä¹³ï¼Œè¢«å‘ç°åè„¸éƒ¨æ½®çº¢ã€‚ ",
         stream=True)
    print(positive_prompt)
    print(negative_prompt)
